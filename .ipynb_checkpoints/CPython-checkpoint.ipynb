{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f069482-725c-45f9-a0ea-12797165bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a223183d-81b5-4947-8fa3-4b1374cc38ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues total records, 70543\n",
      "Pull requests total records, 29300\n",
      "Value counts for type column type\n",
      "issue           70543\n",
      "pull_request    29300\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('github_issues.csv', low_memory=False)\n",
    "df.describe()\n",
    "\n",
    "issues_df = df[df['type'] == 'issue']\n",
    "prs_df = df[df['type'] == 'pull_request']\n",
    "\n",
    "print(f\"Issues total records, {len(issues_df)}\")\n",
    "print(f\"Pull requests total records, {len(prs_df)}\")\n",
    "print(f\"Value counts for type column {df['type'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f97e9dd-a2a0-47cd-8a6e-ad7d638f037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRs WITH skip news label: 14967 (51.1%)\n",
      "PRs WITHOUT skip news label: 14333 (48.9%)\n",
      "Total PRs: 29300\n"
     ]
    }
   ],
   "source": [
    "# The number of PRs, that does require skip-news label and do not require skip-news label\n",
    "skip_count = prs_df[prs_df[\"labels\"].fillna(\"\").str.contains(\"skip news\", case=False, na=False)]\n",
    "non_skip_count = prs_df[~prs_df[\"labels\"].fillna(\"\").str.contains(\"skip news\", case=False, na=False)]\n",
    "\n",
    "total_prs = len(prs_df)\n",
    "skip_percentage = (len(skip_count) / total_prs) * 100\n",
    "non_skip_percentage = (len(non_skip_count) / total_prs) * 100\n",
    "\n",
    "print(f\"PRs WITH skip news label: {len(skip_count)} ({skip_percentage:.1f}%)\")\n",
    "print(f\"PRs WITHOUT skip news label: {len(non_skip_count)} ({non_skip_percentage:.1f}%)\")\n",
    "print(f\"Total PRs: {total_prs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5165134d-7a27-4bd2-9a86-4be1fdf2164b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues WITH skip news label: 4 (0.0%)\n",
      "Issues WITHOUT skip news label: 70539 (100.0%)\n",
      "Total Issues: 70543\n"
     ]
    }
   ],
   "source": [
    "# The number of Issues, that does require skip-news label and do not require skip-news label\n",
    "skip_count = issues_df[issues_df[\"labels\"].fillna(\"\").str.contains(\"skip news\", case=False, na=False)]\n",
    "non_skip_count = issues_df[~issues_df[\"labels\"].fillna(\"\").str.contains(\"skip news\", case=False, na=False)]\n",
    "\n",
    "total_prs = len(issues_df)\n",
    "skip_percentage = (len(skip_count) / total_prs) * 100\n",
    "non_skip_percentage = (len(non_skip_count) / total_prs) * 100\n",
    "\n",
    "print(f\"Issues WITH skip news label: {len(skip_count)} ({skip_percentage:.1f}%)\")\n",
    "print(f\"Issues WITHOUT skip news label: {len(non_skip_count)} ({non_skip_percentage:.1f}%)\")\n",
    "print(f\"Total Issues: {total_prs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2918b7dd-2498-432d-ba8e-e630d8414a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for PRs: pr_status\n",
      "merged    24017\n",
      "open       5283\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Value counts for PRs\n",
    "print(f\"Value counts for PRs: {prs_df['pr_status'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ae076f-50ec-4a20-8e98-9d22c4948cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for Issues\n",
    "def analyze_github_issues(df):\n",
    "    # Create a copy to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    df.loc[:, 'created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df.loc[:, 'closed_at'] = pd.to_datetime(df['closed_at'])\n",
    "    \n",
    "    # Create month columns\n",
    "    # df.loc[:, 'created_month'] = df['created_at'].fillna(\"12-12-1800\").dt.to_period('M')\n",
    "    # df.loc[:, 'closed_month'] = df['closed_at'].dt.to_period('M')\n",
    "    \n",
    "    # Calculate resolution time\n",
    "    # df.loc[:, 'resolution_days'] = (df['closed_at'] - df['created_at']).dt.total_seconds() / (24 * 60 * 60)\n",
    "    \n",
    "    # Calculate monthly statistics\n",
    "    # monthly_stats = df.groupby('created_month').agg({\n",
    "    #     'id': 'count',\n",
    "    #     'state': lambda x: (x == 'CLOSED').sum()\n",
    "    # }).rename(columns={\n",
    "    #     'id': 'created',\n",
    "    #     'state': 'closed'\n",
    "    # })\n",
    "    \n",
    "    # Calculate average resolution time\n",
    "    avg_resolution_time = df[df['resolution_days'].notna()]['resolution_days'].mean()\n",
    "    \n",
    "    return monthly_stats, 12\n",
    "\n",
    "def plot_issue_trends(monthly_stats, avg_resolution_time):\n",
    "    # Set the style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    # Create figure and axis objects with a single subplot\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), height_ratios=[2, 1])\n",
    "    \n",
    "    # Plot created and closed issues\n",
    "    monthly_stats['created'].plot(ax=ax1, label='Created', marker='o')\n",
    "    monthly_stats['closed'].plot(ax=ax1, label='Closed', marker='o')\n",
    "    \n",
    "    ax1.set_title('GitHub Issues Trends')\n",
    "    ax1.set_xlabel('Month')\n",
    "    ax1.set_ylabel('Number of Issues')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot ratio of closed to created issues\n",
    "    ratio = monthly_stats['closed'] / monthly_stats['created']\n",
    "    ratio.plot(ax=ax2, label='Closed/Created Ratio', marker='o')\n",
    "    ax2.axhline(y=1, color='r', linestyle='--', label='1:1 Ratio')\n",
    "    \n",
    "    ax2.set_title(f'Closed/Created Ratio (Avg Resolution Time: {avg_resolution_time:.1f} days)')\n",
    "    ax2.set_xlabel('Month')\n",
    "    ax2.set_ylabel('Ratio')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8909100-9bca-4b9b-8782-589dcade594d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'resolution_days'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/workspace/machine_learning/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'resolution_days'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m monthly_stats, avg_resolution_time \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_github_issues\u001b[49m\u001b[43m(\u001b[49m\u001b[43missues_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m fig \u001b[38;5;241m=\u001b[39m plot_issue_trends(monthly_stats, avg_resolution_time)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36manalyze_github_issues\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      8\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclosed_at\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclosed_at\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create month columns\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# df.loc[:, 'created_month'] = df['created_at'].fillna(\"12-12-1800\").dt.to_period('M')\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# df.loc[:, 'closed_month'] = df['closed_at'].dt.to_period('M')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate average resolution time\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m avg_resolution_time \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresolution_days\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnotna()][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresolution_days\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m monthly_stats, avg_resolution_time\n",
      "File \u001b[0;32m~/workspace/machine_learning/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/workspace/machine_learning/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'resolution_days'"
     ]
    }
   ],
   "source": [
    "monthly_stats, avg_resolution_time = analyze_github_issues(issues_df)\n",
    "fig = plot_issue_trends(monthly_stats, avg_resolution_time)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891fa942-1fb8-4d6d-91b8-e4087ca22110",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_stats, avg_resolution_time = analyze_github_issues(prs_df)\n",
    "fig = plot_issue_trends(monthly_stats, avg_resolution_time)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c148f-6ab1-40a1-95b7-e77f5a639ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_visualizations(issues_data):\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(issues_data)\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df['closed_at'] = pd.to_datetime(df['closed_at'])\n",
    "    df['created_month'] = df['created_at'].dt.to_period('M')\n",
    "    df['created_weekday'] = df['created_at'].dt.day_name()\n",
    "    df['resolution_days'] = (df['closed_at'] - df['created_at']).dt.total_seconds() / (24 * 60 * 60)\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    gs = fig.add_gridspec(3, 2, hspace=0.3)\n",
    "\n",
    "    # 1. Issue Activity Heatmap\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    monthly_activity = df.groupby(['created_month']).size().reset_index(name='count')\n",
    "    monthly_activity['month_num'] = monthly_activity.index\n",
    "    heatmap_data = monthly_activity.pivot_table(\n",
    "        values='count', \n",
    "        index=monthly_activity['month_num'] // 12,\n",
    "        columns=monthly_activity['month_num'] % 12 + 1,\n",
    "    ).fillna(0)\n",
    "    \n",
    "    sns.heatmap(heatmap_data, cmap='YlOrRd', ax=ax1)\n",
    "    ax1.set_title('Issue Activity Heatmap (Years Ã— Months)')\n",
    "    ax1.set_xlabel('Month')\n",
    "    ax1.set_ylabel('Year')\n",
    "\n",
    "    # 2. Resolution Time Distribution\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    closed_issues = df[df['closed_at'].notna()]\n",
    "    sns.histplot(data=closed_issues, x='resolution_days', bins=30, ax=ax2)\n",
    "    ax2.set_title('Distribution of Issue Resolution Times')\n",
    "    ax2.set_xlabel('Days to Resolution')\n",
    "    ax2.set_ylabel('Number of Issues')\n",
    "\n",
    "    # 3. Open vs Closed Issues Over Time\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    df['cumulative_created'] = range(1, len(df) + 1)\n",
    "    closed_cumulative = df[df['closed_at'].notna()].sort_values('closed_at')\n",
    "    closed_cumulative['cumulative_closed'] = range(1, len(closed_cumulative) + 1)\n",
    "    \n",
    "    plt.plot(df['created_at'], df['cumulative_created'], label='Created')\n",
    "    if not closed_cumulative.empty:\n",
    "        plt.plot(closed_cumulative['closed_at'], closed_cumulative['cumulative_closed'], label='Closed')\n",
    "    ax3.set_title('Cumulative Issues Over Time')\n",
    "    ax3.set_xlabel('Date')\n",
    "    ax3.set_ylabel('Number of Issues')\n",
    "    ax3.legend()\n",
    "\n",
    "    # 4. Weekly Pattern\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    weekday_counts = df['created_weekday'].value_counts().reindex(weekday_order)\n",
    "    sns.barplot(x=weekday_counts.index, y=weekday_counts.values, ax=ax4)\n",
    "    ax4.set_title('Issues Created by Day of Week')\n",
    "    ax4.set_xticklabels(weekday_order, rotation=45)\n",
    "    ax4.set_ylabel('Number of Issues')\n",
    "\n",
    "    # 5. Label Distribution\n",
    "    ax5 = fig.add_subplot(gs[2, 0])\n",
    "    labels = [label for sublist in df['labels'] for label in sublist]\n",
    "    label_counts = pd.Series(labels).value_counts()\n",
    "    sns.barplot(x=label_counts.values, y=label_counts.index, ax=ax5)\n",
    "    ax5.set_title('Distribution of Issue Labels')\n",
    "    ax5.set_xlabel('Number of Issues')\n",
    "\n",
    "    # 6. Monthly Velocity\n",
    "    ax6 = fig.add_subplot(gs[2, 1])\n",
    "    monthly_created = df.groupby('created_month').size()\n",
    "    monthly_closed = df[df['closed_at'].notna()].groupby(df['closed_at'].dt.to_period('M')).size()\n",
    "    monthly_velocity = pd.DataFrame({\n",
    "        'Created': monthly_created,\n",
    "        'Closed': monthly_closed\n",
    "    }).fillna(0)\n",
    "    \n",
    "    monthly_velocity.plot(kind='bar', ax=ax6)\n",
    "    ax6.set_title('Monthly Issue Velocity')\n",
    "    ax6.set_xlabel('Month')\n",
    "    ax6.set_ylabel('Number of Issues')\n",
    "    ax6.tick_params(axis='x', rotation=45)\n",
    "    ax6.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472629f8-9c43-4ff0-ad9e-b1e94473fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_analysis_visualizations(issues_df)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
